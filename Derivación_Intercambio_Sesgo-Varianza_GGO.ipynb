{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Para demostrar la siguiente ecuación  \n",
    "\n",
    "$$\\mathbb{E}_{x}\\left[\\mathbb{E}_{\\hat{f}}\\left[\\left(y-\\hat{f}(x)\\right)\\right]\\right] = \\mathbb{E}_{x}\\left[\\text{sesgo}\\left[\\hat{f}(x)\\right]^2\\right] + \\mathbb{E}_{x}\\left[\\text{var}\\left(\\hat{f}(x)\\right)\\right] + \\sigma^2_{\\epsilon}$$\n",
    "\n",
    "Supongamos que la variable $y$ depende de una variable $x$, esta relación puede ser determinista o no, pues puede estar afecta por cierto *ruido* que no puede ser modelado de forma explícita. Dicha relación está dada por una función $f$, la cual asumiremos fija y arbitraria, incluso aunque sea desconocida. Por lo cual, $y$ se puede expresar por medio de la siguiente ecuación \n",
    "\n",
    "$$y = f(x) + \\epsilon$$\n",
    "\n",
    "Además, el ruido $\\epsilon$ es modelado por medio de una variable aleatoria con media cero y varianza $\\sigma^2_{\\epsilon}$. De forma intuitiva, entre mayor incertidumbre se tenga sobre el fenómeno subyacente, la varianza será mayor y viceversa.  \n",
    "\n",
    "$\\therefore \\mathbb{E}\\left[\\epsilon\\right] = 0, \\quad \\mathbb{E}\\left[\\epsilon^2\\right] = \\sigma^2_{\\epsilon}$  \n",
    "\n",
    "Como $f$ es desconocida, intentaremos modelar $f$ a través de una función $\\hat{f}$, la cual se obtendrá por medio de las observaciones (datos) vistos. Claramente, entre más cerca este la distribución generadora de estas observaciones vistas a la distribución real subyacente del fenómeno en estudio, el modelo representado por la función $\\hat{f}$ logrará generalizar mejor observaciones no vistas por el modelo inicial. La función $\\hat{f}$ es *aprendida* al minimizar una **función de pérdida**, cuya finalidad es lograr obtener predicciones, lo más cercanas posibles al valor verdadero, a través de los datos observados, es decir, $y \\approx \\hat{f}(x)$    \n",
    "\n",
    "  \n",
    "$MSE$, error cuadrático medio, por sus siglas en inglés, es el promedio del cuadrado de las diferencias de una predicción $\\hat{f}(x)$ y el valor real $y$. Se define como $$MSE = \\mathbb{E}\\left[\\left(y - \\hat{f}(x)\\right)^2\\right]$$  \n",
    "\n",
    "por otro lado, se define el *Sesgo* como la diferencia del valor esperado del valor predicho de $\\hat{f}(x)$ y el verdadero valor de $f$ evaluado en un valor no observado $x$. Notemos que $\\hat{f}$ es una variable aleatoria que depende de la aleatoriedad por la cual obtuvimos los valores observados.\n",
    "\n",
    "Por último, la varianza se define como el promedio del cuadrado de las desviaciones de $\\hat{f}(x)$ de su valor esperado $\\mathbb{E}\\left[\\hat{f}(x)\\right]$, a través de distintas realizaciones del conjunto de datos $$var\\left(\\hat{f}(x)\\right) = \\mathbb{E}\\left[\\left(\\hat{f}(x) - \\mathbb{E}\\left[\\hat{f}(x)\\right]\\right)^2\\right]$$\n",
    "\n",
    "Teniendo todo lo anterior en mente, supongamos que $x$ es un dato no observado previamente, $f$ es la función real subyante, la cual dicta la relación entre $x$ y $y$, la cual es desconocida pero fija y $\\epsilon$ representa el *ruido*  inherente al problema. El $MSE$, $\\mathbb{E}\\left[(y-\\hat{f}(x))^2\\right]$ depende de diferentes realizaciones del conjunto de entrenamiento, teniendo la siguiente forma\n",
    "\n",
    "\\begin{align} \n",
    "\\mathbb{E}\\left[(y-\\hat{f}(x))^2\\right] &=  \\mathbb{E}\\left[\\left(f(x) + \\epsilon - \\hat{f}(x)\\right)^2\\right]\\\\ \n",
    " &= \\mathbb{E}\\left[\\left(f(x)-\\hat{f}(x)\\right)^2\\right] + \\mathbb{E}\\left[\\epsilon^2\\right] + 2\\mathbb{E}\\left[\\left(f(x)-\\hat{f}(x)\\right)\\cdot \\epsilon\\right]\\\\\n",
    " &= \\mathbb{E}\\left[\\left(f(x)-\\hat{f}(x)\\right)^2\\right] + \\sigma^2_{\\epsilon} + 2\\mathbb{E}\\left[\\left(f(x)-\\hat{f}(x)\\right)\\right]\\cdot\\mathbb{E}\\left[\\epsilon\\right]\\\\\n",
    "&= \\mathbb{E}\\left[\\left(f(x)-\\hat{f}(x)\\right)^2\\right] + \\sigma^2_{\\epsilon} \n",
    "\\end{align}\n",
    "\n",
    "Ahora, haciendo énfasis en la componente $\\mathbb{E}\\left[\\left(f(x)-\\hat{f}(x)\\right)^2\\right]$, se tiene que\n",
    "\n",
    "\\begin{align} \n",
    "\\mathbb{E}\\left[\\left(f(x)-\\hat{f}(x)\\right)^2\\right] &= \\mathbb{E}\\left[\\left(\\left(f(x) - \\mathbb{E}\\left[\\hat{f}(x)\\right]\\right) - \\left(\\hat{f}(x)-\\mathbb{E}\\left[\\hat{f}(x)\\right]\\right)\\right)^2\\right]\\\\\n",
    "&= \\mathbb{E}\\left[\\left(\\mathbb{E}\\left[\\hat{f}(x)\\right] - f(x)\\right)^2\\right] + \\mathbb{E}\\left[\\left(\\hat{f}(x)-\\mathbb{E}\\left[\\hat{f}(x)\\right]\\right)^2\\right] - 2\\mathbb{E}\\left[\\left(f(x)-\\mathbb{E}\\left[\\hat{f}(x)\\right]\\right)\\left(\\hat{f}(x)-\\mathbb{E}\\left[\\hat{f}(x)\\right]\\right)\\right]\\\\\n",
    "&= \\left(\\mathbb{E}\\left[\\hat{f}(x)\\right] - f(x)\\right)^2 + \\mathbb{E}\\left[\\left(\\hat{f}(x)-\\mathbb{E}\\left[\\hat{f}(x)\\right]\\right)^2\\right] - 2\\left(f(x)-\\mathbb{E}\\left[\\hat{f}(x)\\right]\\right)\\mathbb{E}\\left[\\left(\\hat{f}(x)-\\mathbb{E}\\left[\\hat{f}(x)\\right]\\right)\\right]\\\\\n",
    "&= sesgo\\left[\\hat{f}(x)\\right]^2 + var\\left(\\hat{f}(x)\\right) - 2\\left(f(x)-\\mathbb{E}\\left[\\hat{f}(x)\\right]\\right)\\left(\\mathbb{E}\\left[\\hat{f}(x)\\right]-\\mathbb{E}\\left[\\hat{f}(x)\\right]\\right)\\\\\n",
    "&= sesgo\\left[\\hat{f}(x)\\right]^2 + var\\left(\\hat{f}(x)\\right)\n",
    "\\end{align}\n",
    "\n",
    "$\\implies \\mathbb{E}\\left[(y-\\hat{f}(x))^2\\right] = sesgo\\left[\\hat{f}(x)\\right]^2 + var\\left(\\hat{f}(x)\\right) + \\sigma^2_{\\epsilon}$  \n",
    "  \n",
    "Sin embargo, lo anterior es únicamente para un punto $x$, sin embargo, dado un conjunto de puntos $X$, y suponiendo que $X$ tiene una función de probabilidad asociada, se tiene que al obtener la esperanza sobre la expresión anterior, derivado de que $x \\sim P_X$\n",
    "\n",
    "$$\\therefore \\mathbb{E}_{x}\\left[\\mathbb{E}_{\\hat{f}}\\left[\\left(y-\\hat{f}(x)\\right)\\right]\\right] = \\mathbb{E}_{x}\\left[\\text{sesgo}\\left[\\hat{f}(x)\\right]^2\\right] + \\mathbb{E}_{x}\\left[\\text{var}\\left(\\hat{f}(x)\\right)\\right] + \\sigma^2_{\\epsilon}$$"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
